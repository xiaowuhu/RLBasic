
## 1.3 运筹学与强化学习

运筹学（operations research，OR）与优化问题（optimization）对于大多数人来说比较陌生，在《中国科学院院刊》中关于“运筹学发展的回顾与展望”这样介绍：主要研究人类对各种资源的运用及筹划活动，以期通过了解和发展这种运用及筹划活动的基本规律，发挥有限资源的最大效益，达到总体最优的目标。而《史记·高祖本纪》中的“运筹帷幄之中，决胜千里之外”应该是大家最耳熟能详的对这个问题的描述了。

在强化学习出现之前，一直使用运筹学来解决实际问题。后来发现有一些问题使用运筹学得到的解不令人满意（准确度低、效率低），于是转而使用强化学习来解决。而二者的目标是一样的，都是要做出决策。但是并非强化学习比运筹学好，而是二者各有优势。

以中国石油公司为例，随着汽车工业的发展，2018年中国的石油消耗量在过去的五年中已经翻倍了。中石油与来自加利福尼亚、伯克利、清华等几所大学的研究人员合作开发了新的软件，来优化国内的资源分配线。以前，这些都是用手工表格方式完成的，易出错，成本高；而现在，经过几年的对新软件的使用，中石油已经节约了3.3亿美元的成本。

但是更复杂的变量和约束的引入，会让运筹学一筹莫展，面对这类问题，人们会期待运筹学有如下表现：提高数据分析的效率、提高预测能力、发现/发明更好的技术、改进日程安排和时间管理、增加风险管理。而此时，强化学习的出现带来了新的机遇。在后面的章节中我们在细说强化学习，这里先简单比较一下运筹学和强化学习的区别。见表 1.3.1。

表 1.3.1 运筹学和强化学习的比较

||运筹学|强化学习|
|-|-|-|
|理论基础|数学理论|应用场景|
|场景设定|静态|动态|
|解决方案|准确|不确定|
|可解释性|容易解释|很难解释|
|数据要求|低|高|
|计算成本|根据问题而定|根据问题而定|

笔者在这里暂时不对表 1.3.1 做过多的解释，因为读者可能对于这两者都不了解，等读者学习完本书后，再回过头来自行理解此表中的内容。但是这里可以举另外一个例子来说明二者的区别：

一个跨国海运公司在世界各地的港口都有空的集装箱，需要及时地转运到所需要的港口装载货物。如果用传统的运筹学中的优化算法，每次计算需要花费好几天的时间，而且还不能克服一些临时的因素造成的误差，造成空集装箱没有正确地达到需要的港口，因为货船一旦离港，就很难重新规划航线。因此，研究员们利用多智能体强化学习的算法，成功地解决了这个问题，每次规划航线只需要几分钟的时间，而且根据新的变量和约束的输入，可以随时重新规划。
