# 第三步 动态规划与贝尔曼方程

# 第 5 章 状态价值函数与贝尔曼方程

【温故知新】从价值估算升级到价值计算。

在第 4 章中，我们学习了强化学习的基本而重要的概念，奖励、回报、MRP、状态价值函数、价值评估等，后续的所有关于强化学习的目标都是围绕**价值函数**计算的。但是价值评估所使用的采样方法在有模型（即知道转移概率矩阵）的环境中效率太低，需要大量的采样然后求平均值，才能得到估算值。因为我们无法衡量什么叫做准确，所以称之为**估算**。

但是，在有模型的环境中的转移概率都是确定的，所以在本章中，我们将学习著名的**贝尔曼方程**，使用**动态规划**的方法来解决有模型问题的价值函数**计算**过程。而对于无模型（不知道转移概率矩阵）的环境问题以及更多的蒙特卡洛方法，将会在第 9 章中继续介绍。
