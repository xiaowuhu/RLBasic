# 第 6 章 动作价值函数与贝尔曼期望方程

【温故知新】从状态价值升级到动作价值。

在第 5 章中，我们利用贝尔曼方程可以解决比较复杂的 MRP 问题，它描述了一种转移概率的规律，并计算出来**状态价值**。但是我们并没有仔细考察这些转移概率是如何发生的，也就是说只看到了现象，不知道原因，所以只能说是一种统计的结果。

在本章中，我们仍然以前面学过的的转移概率问题来开始本章的学习，通过动手实验来发现这种方法的不足，然后引入新的概念，以便可以解决更复杂的问题。具体来说，引入了**策略与动作**的概念，把简单的状态转移变成了“状态$\to$策略$\to$动作$\to$转移”，进而产生了**马尔可夫决策过程**和**贝尔曼期望方程**，计算出**动作价值**，以符合客观世界的建模要求。
